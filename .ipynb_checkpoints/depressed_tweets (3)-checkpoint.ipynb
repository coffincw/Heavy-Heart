{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import tweepy\n",
    "import io\n",
    "import time\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import pandas\n",
    "test_data=[]\n",
    "train_control=[]\n",
    "train_depressed=[]\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'n4zRm3xuVoYoBHDLbSSqCxlII'\n",
    "consumer_secret = 'i2bxYM53rVNv0NFnO4iALdUYUDXHSEp9JARjpSu6290B5W6BLj'\n",
    "access_token = '3265727682-sWioD71Vv1zJie1KCERyHZWgzCdDsGAy3lzdLJA'\n",
    "access_token_secret = 'Ir9vMlPyiJwafcqXOiRJgtdWpev2VU3rI0Z2MWXlJ79SV'\n",
    "\n",
    "        # attempt authentication\n",
    "try:\n",
    "            # create OAuthHandler object\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "    api = tweepy.API(auth)\n",
    "except:\n",
    "    print(\"Error: Authentication Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "\tusing textblob's sentiment method\n",
    "\t\"\"\"\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query, count=10):\n",
    "        \"\"\"\n",
    "\t\tMain function to fetch tweets and parse them.\n",
    "\t\t\"\"\"\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = api.search(q=query, count=count)\n",
    "\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = clean_tweet(tweet.text)\n",
    "\n",
    "                # saving text of tweet\n",
    "                # saving sentiment of tweet\n",
    "\n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    "\n",
    "                # return parsed tweets\n",
    "            return tweets\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_depressed = get_tweets(query=\"#depressed\",count = 50)\n",
    "# train_depressed = list(filter(lambda x:get_tweet_sentiment(tweet=x)==\"negative\",train_depressed))\n",
    "# train_control = get_tweets(query=\"the\",count = 50)\n",
    "# test_data = get_tweets(query=\"#anxiety\",count = 50)\n",
    "keywords2 = [\"e%20\",\"s%20\"]\n",
    "keywords = [\"I need someone to talk to\", \"depressed\", \"wanna talk to someone\", \"want to talk to someone\", \"#depressed\",\n",
    "                \"#depression\", \"lonely\", \"alone\", \"sad\", \"i'm worthless\", \"falling apart\", \"disappointed in myself\", \"i'm the worst\",\n",
    "                \"i'm useless\", \"i am useless\", \"i'm a failure\", \"I am a failure\", \"too much pain\", \"unfair\", \"i'm not happy\",\n",
    "                \"i am not happy\", \"unhappy\", \"regret\", \"have no one\", \"I don't know what to do\", \"i'm lost\", \"i am lost\", \"i am so lost\",\n",
    "                \"hate me\", \"kill myself\", \"end myself\", \"end my life\", \"I want to die\", \"I want to commit suicide\",\n",
    "                \"i'm no good\", \"feel like shit\", \"i feel invisible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_json():\n",
    "    import json\n",
    "    for x in train_depressed:\n",
    "        data.append({\"text\":x,\"label\":\"depressed\"})\n",
    "    for x in train_control:\n",
    "        data.append({\"text\":x,\"label\":\"not depressed\"})\n",
    "    with io.open('train.json','w') as fp:\n",
    "        json.dump(data,fp)\n",
    "#save_data_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_twitter():\n",
    "    import json\n",
    "    i=0\n",
    "    minutes=16\n",
    "    train_depressed = set(train_depressed)\n",
    "    train_control = set(train_control)\n",
    "    while(len(train_depressed)<1000):\n",
    "        train_depressed.append(get_tweets(query=keywords[i%len(keywords)],count = 100))\n",
    "        train_depressed = list(filter(lambda x:get_tweet_sentiment(tweet=x)==\"negative\",train_depressed))\n",
    "        print(\"len of train depressed: %d\",len(train_depressed))\n",
    "        time.sleep(60*minutes)\n",
    "        train_control.append(get_tweets(query=keywords2[i%len(keywords2)],count = 100))\n",
    "        print(\"len of train depressed: %d\",len(train_control))\n",
    "        time.sleep(60*minutes)\n",
    "    train_control = list(train_control)\n",
    "    train_depressed = list(train_depressed)\n",
    "crawl_twitter();\n",
    "save_data_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('train.json','r') as fp:\n",
    "    cl = NaiveBayesClassifier(fp,format='json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "48\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "print(len(train_control))\n",
    "print(len(train_depressed))  \n",
    "# print(train_control)\n",
    "# print(train_depressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before running, set the map of the grouped reviews to their respective dictionaries.\n",
    "\"\"\"\n",
    "def is_depressed(review):\n",
    "  if(is_depressed.counter==0):#define probabilities\n",
    "      is_depressed.lenP = 0\n",
    "      is_depressed.lenN = 0\n",
    "      is_depressed.countMapD = {}#depressed revieww \n",
    "      is_depressed.countMapC = {}#Control review\n",
    "      print(\"defining probabilities, this will take a while\")\n",
    "      for depressedReview in train_depressed:\n",
    "          for word in depressedReview:\n",
    "              is_depressed.lenP+=1\n",
    "              if(is_depressed.countMapD.__contains__(word)):\n",
    "                  tempDic = {word: is_depressed.countMapD.get(word) + 1}\n",
    "                  is_depressed.countMapD.update(tempDic)\n",
    "              else:\n",
    "                  is_depressed.countMapD.update({word: 1})\n",
    "      for controlReview in train_control:\n",
    "          for word in controlReview:\n",
    "              is_depressed.lenN+=1\n",
    "              if (is_depressed.countMapC.__contains__(word)):\n",
    "                  tempDic = {word: is_depressed.countMapC.get(word) + 1}\n",
    "                  is_depressed.countMapC.update(tempDic)\n",
    "              else:\n",
    "                  is_depressed.countMapC.update({word: 1})\n",
    "  is_depressed.counter+=1\n",
    "  logProductP = 0\n",
    "  logProductN = 0\n",
    "  probPos = float(is_depressed.lenP)/float(is_depressed.lenP+is_depressed.lenN)\n",
    "  probNeg = float(is_depressed.lenN)/float(is_depressed.lenP+is_depressed.lenN)\n",
    "  for word in review:\n",
    "      logProductN += math.log(float(is_depressed.countMapC.get(word,1)))\n",
    "      logProductP += math.log(float(is_depressed.countMapD.get(word,1)))\n",
    "  return logProductP-math.log(float(is_depressed.lenP))>logProductN-math.log(float(is_depressed.lenN))\n",
    "\n",
    "is_depressed.counter = 0\n",
    "is_depressed.lenP = 0\n",
    "is_depressed.lenN = 0\n",
    "is_depressed.countMapD = {}\n",
    "is_depressed.countMapC = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.001\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n",
      "0.0\n",
      "not depressed\n"
     ]
    }
   ],
   "source": [
    "for x in test_data:\n",
    "    print(round(cl.prob_classify(x).prob(\"depressed\"),3))\n",
    "    print(cl.prob_classify(x).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
