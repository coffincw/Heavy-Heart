{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'n4zRm3xuVoYoBHDLbSSqCxlII'\n",
    "consumer_secret = 'i2bxYM53rVNv0NFnO4iALdUYUDXHSEp9JARjpSu6290B5W6BLj'\n",
    "access_token = '3265727682-sWioD71Vv1zJie1KCERyHZWgzCdDsGAy3lzdLJA'\n",
    "access_token_secret = 'Ir9vMlPyiJwafcqXOiRJgtdWpev2VU3rI0Z2MWXlJ79SV'\n",
    "\n",
    "        # attempt authentication\n",
    "try:\n",
    "            # create OAuthHandler object\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "    api = tweepy.API(auth)\n",
    "except:\n",
    "    print(\"Error: Authentication Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(self, tweet):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "\tusing textblob's sentiment method\n",
    "\t\"\"\"\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(self.clean_tweet(tweet))\n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before running, set the map of the grouped reviews to their respective dictionaries.\n",
    "\"\"\"\n",
    "def is_depressed(review):\n",
    "  if(is_depressed.counter==0):#define probabilities\n",
    "      is_depressed.lenP = 0\n",
    "      is_depressed.lenN = 0\n",
    "      is_depressed.countMapD = {}#depressed revieww \n",
    "      is_depressed.countMapC = {}#Control review\n",
    "      print(\"defining probabilities, this will take a while\")\n",
    "      for depressedReview in train_depressed:\n",
    "          for word in depressedReview:\n",
    "              is_depressed.lenP+=1\n",
    "              if(is_depressed.countMapD.__contains__(word)):\n",
    "                  tempDic = {word: is_depressed.countMapD.get(word) + 1}\n",
    "                  is_depressed.countMapD.update(tempDic)\n",
    "              else:\n",
    "                  is_depressed.countMapD.update({word: 1})\n",
    "      for controlReview in train_control:\n",
    "          for word in controlReview:\n",
    "              is_depressed.lenN+=1\n",
    "              if (is_depressed.countMapC.__contains__(word)):\n",
    "                  tempDic = {word: is_depressed.countMapC.get(word) + 1}\n",
    "                  is_depressed.countMapC.update(tempDic)\n",
    "              else:\n",
    "                  is_depressed.countMapC.update({word: 1})\n",
    "  is_depressed.counter+=1\n",
    "  logProductP = 0\n",
    "  logProductN = 0\n",
    "  probPos = float(is_depressed.lenP)/float(is_depressed.lenP+is_depressed.lenN)\n",
    "  probNeg = float(is_depressed.lenN)/float(is_depressed.lenP+is_depressed.lenN)\n",
    "  for word in review:\n",
    "      logProductN += math.log(float(is_depressed.countMapC.get(word,1)))\n",
    "      logProductP += math.log(float(is_depressed.countMapD.get(word,1)))\n",
    "  return logProductP-math.log(float(is_depressed.lenP))>logProductN-math.log(float(is_depressed.lenN))\n",
    "\n",
    "is_depressed.counter = 0\n",
    "is_depressed.lenP = 0\n",
    "is_depressed.lenN = 0\n",
    "is_depressed.countMapD = {}\n",
    "is_depressed.countMapC = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query, count=10):\n",
    "        \"\"\"\n",
    "\t\tMain function to fetch tweets and parse them.\n",
    "\t\t\"\"\"\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = api.search(q=query, count=count)\n",
    "\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = clean_tweet(tweet.text)\n",
    "\n",
    "                # saving text of tweet\n",
    "                # saving sentiment of tweet\n",
    "\n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    "\n",
    "                # return parsed tweets\n",
    "            return tweets\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_depressed = get_tweets(query=\"#depressed\",count = 500)\n",
    "train_control = get_tweets(query=\"a\",count = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(train_control))\n",
    "print(len(train_depressed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for x in train_control:\n",
    "    print(is_depressed(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
